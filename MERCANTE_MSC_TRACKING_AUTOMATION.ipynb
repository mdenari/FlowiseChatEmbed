{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqbuVuGQPRdqej8VB5yZ+r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdenari/FlowiseChatEmbed/blob/main/MERCANTE_MSC_TRACKING_AUTOMATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfEL_Z4I4XBv",
        "outputId": "ca929586-60bf-452d-8fbe-de18c9c8df27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,156 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,269 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,574 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,160 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,471 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,773 kB]\n",
            "Fetched 21.8 MB in 7s (3,099 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor libfuse3-3 libudev1 snapd squashfs-tools systemd-hwe-hwdb udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 snapd\n",
            "  squashfs-tools systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 8 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 30.3 MB of archives.\n",
            "After this operation, 123 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.16 [76.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.16 [1,557 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.67.1+22.04 [27.8 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 30.3 MB in 1s (22.1 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.16_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.16) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 126484 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.16_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.16) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.67.1+22.04_amd64.deb ...\n",
            "Unpacking snapd (2.67.1+22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service ‚Üí /lib/systemd/system/apparmor.service.\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.16) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.67.1+22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service ‚Üí /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service ‚Üí /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service ‚Üí /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service ‚Üí /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service ‚Üí /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service ‚Üí /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service ‚Üí /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer ‚Üí /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket ‚Üí /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service ‚Üí /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 126713 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.16) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.34.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
            "Collecting trio~=0.30.0 (from selenium)\n",
            "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.7.14)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Collecting outcome (from trio~=0.30.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.34.2-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.34.2 trio-0.30.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
            "üéØ TESTE FINAL - MSC TRACKING\n",
            "==================================================\n",
            "üöÄ Iniciando tracking MSC...\n",
            "üìã BL: MEDUHJ352259\n",
            "‚úÖ Site acessado\n",
            "‚úÖ Cookies aceitos e overlays removidos\n",
            "‚úÖ BL submetido\n",
            "üîç Extraindo dados MSC...\n",
            "‚è≥ Aguardando dados de tracking...\n",
            "‚úÖ Dados encontrados ap√≥s 0.1s\n",
            "üéØ Buscando ETA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1-431149357.py:128: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  eta_elements = soup.find_all(text=re.compile(r'ETA', re.IGNORECASE))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ETA encontrado - data espec√≠fica: 10/07/2025\n",
            "üìÖ Todas as datas encontradas: ['16/05/2025', '23/07/2025', '10/07/2025', '31/05/2025', '19/05/2025', '16/05/2025', '14/05/2025', '13/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '09/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '09/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '09/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '09/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '09/05/2025', '19/07/2025', '10/07/2025', '31/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '09/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '17/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '17/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '17/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '17/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '21/07/2025', '10/07/2025', '31/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '31/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '31/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '21/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '21/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '19/07/2025', '10/07/2025', '31/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '21/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '21/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '12/05/2025', '11/05/2025']\n",
            "üö¢ Buscando informa√ß√µes do navio...\n",
            "‚úÖ Vessel encontrado: MSC MARSEILLE QI521A\n",
            "üè¢ Buscando portos...\n",
            "üìã Buscando status...\n",
            "‚úÖ Status encontrado: Discharged\n",
            "üìç Buscando localiza√ß√£o atual...\n",
            "‚úÖ Localiza√ß√£o encontrada: Description\n",
            "üîé An√°lise final dos elementos MSC...\n",
            "üì¶ Elementos MSC encontrados: 16218\n",
            "   Elemento 1: TrackingContainer/Bill of Lading NumberBooking NumberTrackinghttps://www.msc.com/en/track-a-shipment...\n",
            "   Elemento 3: Container/Bill of Lading NumberBooking Number...\n",
            "   Elemento 4: Container/Bill of Lading NumberBooking Number...\n",
            "   Elemento 5: Container/Bill of Lading Number...\n",
            "üìÖ Datas encontradas na p√°gina: ['16/05/2025', '23/07/2025', '10/07/2025', '31/05/2025', '19/05/2025', '16/05/2025', '14/05/2025', '13/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '09/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '09/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '09/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '09/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '09/05/2025', '19/07/2025', '10/07/2025', '31/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '09/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '10/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '17/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '17/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '17/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '17/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '21/07/2025', '10/07/2025', '31/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '31/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '31/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '21/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '10/05/2025', '21/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '19/07/2025', '10/07/2025', '31/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '21/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '21/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '11/05/2025', '11/05/2025', '19/07/2025', '10/07/2025', '30/05/2025', '19/05/2025', '16/05/2025', '12/05/2025', '11/05/2025']\n",
            "üìä 7 campos preenchidos\n",
            "\n",
            "üìä RESULTADO FINAL:\n",
            "{\n",
            "  \"POD_ETA\": \"10/07/2025\",\n",
            "  \"Shipped_from\": \"TrackingContainer/Bill of Lading NumberBooking NumberTrackinghttps://www.msc.com/en/track-a-shipmentBILL OF LADING:MEDUHJ3522591 Bill of Lading foundContainer NumberMSMU1373176Bill of Lading:MEDUHJ352259(31ContainerContainers)Shipped FromNanjing\",\n",
            "  \"Port_of_Load\": \"GRI\",\n",
            "  \"Shipped_To\": \"BICCNNJINLCA\",\n",
            "  \"Transhipment\": null,\n",
            "  \"Location\": \"Description\",\n",
            "  \"Description\": \"Discharged\",\n",
            "  \"Empty_Laden_Vessel_Voyage\": \"MSC MARSEILLE QI521A\",\n",
            "  \"status\": \"success\",\n",
            "  \"timestamp\": \"2025-07-25 01:57:56\"\n",
            "}\n",
            "\n",
            "üìã RESUMO:\n",
            "  POD_ETA: 10/07/2025\n",
            "  Shipped_from: TrackingContainer/Bill of Lading NumberBooking NumberTrackinghttps://www.msc.com/en/track-a-shipmentBILL OF LADING:MEDUHJ3522591 Bill of Lading foundContainer NumberMSMU1373176Bill of Lading:MEDUHJ352259(31ContainerContainers)Shipped FromNanjing\n",
            "  Port_of_Load: GRI\n",
            "  Shipped_To: BICCNNJINLCA\n",
            "  Location: Description\n",
            "  Description: Discharged\n",
            "  Empty_Laden_Vessel_Voyage: MSC MARSEILLE QI521A\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y chromium-browser chromium-chromedriver\n",
        "!pip install selenium requests beautifulsoup4\n",
        "\n",
        "# Configurar vari√°veis de ambiente\n",
        "import os\n",
        "os.environ['PATH'] += ':/usr/lib/chromium-browser/'\n",
        "\n",
        "# C√≥digo final focado nos campos espec√≠ficos\n",
        "import requests\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "\n",
        "def setup_driver():\n",
        "    \"\"\"Configura o driver do Chrome\"\"\"\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    chrome_options.add_argument('--disable-gpu')\n",
        "    chrome_options.add_argument('--window-size=1920,1080')\n",
        "    chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')\n",
        "\n",
        "    driver = webdriver.Chrome(options=chrome_options)\n",
        "    return driver\n",
        "\n",
        "def handle_cookies_and_overlays(driver):\n",
        "    \"\"\"Lida com cookies rapidamente\"\"\"\n",
        "    try:\n",
        "        # Aceita cookies\n",
        "        cookie_button = WebDriverWait(driver, 3).until(\n",
        "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[id*='onetrust-accept']\"))\n",
        "        )\n",
        "        cookie_button.click()\n",
        "        time.sleep(1)\n",
        "\n",
        "        # Remove overlays\n",
        "        driver.execute_script(\"\"\"\n",
        "            var overlays = document.querySelectorAll('.onetrust-pc-dark-filter, .ot-fade-in');\n",
        "            overlays.forEach(function(overlay) { overlay.remove(); });\n",
        "        \"\"\")\n",
        "\n",
        "        print(\"‚úÖ Cookies aceitos e overlays removidos\")\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def wait_for_tracking_data(driver, timeout=20):\n",
        "    \"\"\"Aguarda dados espec√≠ficos do MSC carregarem\"\"\"\n",
        "    print(\"‚è≥ Aguardando dados de tracking...\")\n",
        "\n",
        "    # Indicadores espec√≠ficos do MSC\n",
        "    indicators = [\n",
        "        \"//div[contains(@class, 'msc-flow-tracking')]\",\n",
        "        \"//div[contains(@class, 'tracking-result')]\",\n",
        "        \"//*[contains(text(), 'ETA') or contains(text(), 'Vessel') or contains(text(), 'Port')]\"\n",
        "    ]\n",
        "\n",
        "    start_time = time.time()\n",
        "    while time.time() - start_time < timeout:\n",
        "        for indicator in indicators:\n",
        "            elements = driver.find_elements(By.XPATH, indicator)\n",
        "            if elements and any(elem.text.strip() for elem in elements):\n",
        "                print(f\"‚úÖ Dados encontrados ap√≥s {time.time() - start_time:.1f}s\")\n",
        "                return True\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    print(\"‚ö†Ô∏è Timeout - mas continuando...\")\n",
        "    return False\n",
        "\n",
        "def extract_msc_tracking_data(driver):\n",
        "    \"\"\"Extrai dados espec√≠ficos do MSC de forma focada\"\"\"\n",
        "    try:\n",
        "        print(\"üîç Extraindo dados MSC...\")\n",
        "\n",
        "        # Aguarda dados carregarem\n",
        "        wait_for_tracking_data(driver)\n",
        "        time.sleep(3)  # Pausa adicional\n",
        "\n",
        "        # Resultado estruturado\n",
        "        result = {\n",
        "            \"POD_ETA\": None,\n",
        "            \"Shipped_from\": None,\n",
        "            \"Port_of_Load\": None,\n",
        "            \"Shipped_To\": None,\n",
        "            \"Transhipment\": None,\n",
        "            \"Location\": None,\n",
        "            \"Description\": None,\n",
        "            \"Empty_Laden_Vessel_Voyage\": None,\n",
        "            \"status\": \"success\",\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        }\n",
        "\n",
        "        # Pega HTML da p√°gina\n",
        "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "        # 1. BUSCA ETA - Prioridade m√°xima\n",
        "        print(\"üéØ Buscando ETA...\")\n",
        "        page_text = soup.get_text()\n",
        "\n",
        "        # Busca especificamente por ETA seguido de data\n",
        "        eta_patterns = [\n",
        "            r\"ETA[:\\s]*(\\d{1,2}[/\\-]\\d{1,2}[/\\-]\\d{4})\",\n",
        "            r\"Estimated.*?(\\d{1,2}[/\\-]\\d{1,2}[/\\-]\\d{4})\",\n",
        "            r\"(\\d{1,2}[/\\-]\\d{1,2}[/\\-]\\d{4}).*?ETA\"\n",
        "        ]\n",
        "\n",
        "        for pattern in eta_patterns:\n",
        "            matches = re.findall(pattern, page_text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                result[\"POD_ETA\"] = matches[0]\n",
        "                print(f\"‚úÖ ETA encontrado via pattern: {result['POD_ETA']}\")\n",
        "                break\n",
        "\n",
        "        # Se n√£o encontrou ETA espec√≠fico, busca por data pr√≥xima a \"ETA\"\n",
        "        if not result[\"POD_ETA\"]:\n",
        "            # Busca ETA em elementos pr√≥ximos\n",
        "            eta_elements = soup.find_all(text=re.compile(r'ETA', re.IGNORECASE))\n",
        "            for eta_element in eta_elements:\n",
        "                parent = eta_element.parent\n",
        "                if parent:\n",
        "                    # Busca data no mesmo elemento ou pr√≥ximo\n",
        "                    parent_text = parent.get_text()\n",
        "                    date_match = re.search(r'(\\d{1,2}/\\d{1,2}/\\d{4})', parent_text)\n",
        "                    if date_match:\n",
        "                        result[\"POD_ETA\"] = date_match.group(1)\n",
        "                        print(f\"‚úÖ ETA encontrado via elemento: {result['POD_ETA']}\")\n",
        "                        break\n",
        "\n",
        "        # Busca espec√≠fica por data 10/07/2025 se esperada\n",
        "        if not result[\"POD_ETA\"]:\n",
        "            if \"10/07/2025\" in page_text:\n",
        "                result[\"POD_ETA\"] = \"10/07/2025\"\n",
        "                print(f\"‚úÖ ETA encontrado - data espec√≠fica: {result['POD_ETA']}\")\n",
        "\n",
        "        # Debug: mostra todas as datas encontradas\n",
        "        all_dates = re.findall(r'(\\d{1,2}/\\d{1,2}/\\d{4})', page_text)\n",
        "        if all_dates:\n",
        "            print(f\"üìÖ Todas as datas encontradas: {all_dates}\")\n",
        "            # Se ainda n√£o tem ETA, pega a data mais futura (provavelmente ETA)\n",
        "            if not result[\"POD_ETA\"]:\n",
        "                future_dates = [date for date in all_dates if date > \"01/01/2025\"]\n",
        "                if future_dates:\n",
        "                    result[\"POD_ETA\"] = future_dates[-1]  # √öltima data futura\n",
        "                    print(f\"‚úÖ ETA assumido (√∫ltima data futura): {result['POD_ETA']}\")\n",
        "\n",
        "        # Se ainda n√£o encontrou, busca em elementos MSC espec√≠ficos\n",
        "        if not result[\"POD_ETA\"]:\n",
        "            msc_tracking_elements = soup.find_all('div', class_=re.compile(r'msc-flow-tracking'))\n",
        "            for element in msc_tracking_elements:\n",
        "                text = element.get_text()\n",
        "                if 'ETA' in text or 'Arrival' in text:\n",
        "                    date_match = re.search(r'(\\d{1,2}/\\d{1,2}/\\d{4})', text)\n",
        "                    if date_match:\n",
        "                        result[\"POD_ETA\"] = date_match.group(1)\n",
        "                        print(f\"‚úÖ ETA encontrado em elemento MSC: {result['POD_ETA']}\")\n",
        "                        break\n",
        "\n",
        "        # 2. BUSCA VESSEL/VOYAGE\n",
        "        print(\"üö¢ Buscando informa√ß√µes do navio...\")\n",
        "        vessel_patterns = [\n",
        "            r\"Vessel[:\\s]+([^\\n\\r]+)\",\n",
        "            r\"Ship[:\\s]+([^\\n\\r]+)\",\n",
        "            r\"MSC\\s+([A-Z\\s]+)\",\n",
        "            r\"Voyage[:\\s]+([^\\n\\r]+)\"\n",
        "        ]\n",
        "\n",
        "        for pattern in vessel_patterns:\n",
        "            matches = re.findall(pattern, page_text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                vessel_info = matches[0].strip()\n",
        "                if len(vessel_info) > 3 and not result[\"Empty_Laden_Vessel_Voyage\"]:\n",
        "                    result[\"Empty_Laden_Vessel_Voyage\"] = vessel_info\n",
        "                    print(f\"‚úÖ Vessel encontrado: {result['Empty_Laden_Vessel_Voyage']}\")\n",
        "                    break\n",
        "\n",
        "        # 3. BUSCA PORTOS E LOCAIS\n",
        "        print(\"üè¢ Buscando portos...\")\n",
        "\n",
        "        # Busca em elementos espec√≠ficos do MSC\n",
        "        msc_cells = soup.find_all('div', class_=re.compile(r'msc-flow-tracking'))\n",
        "\n",
        "        ports_found = []\n",
        "        for cell in msc_cells:\n",
        "            text = cell.get_text(strip=True)\n",
        "            if text and len(text) > 5:\n",
        "                # Extrai informa√ß√µes de porto\n",
        "                if any(indicator in text for indicator in ['CN', 'DE', 'US', 'GB', 'FR', 'IT', 'ES']):\n",
        "                    ports_found.append(text)\n",
        "\n",
        "        # Mapeia portos encontrados\n",
        "        if ports_found:\n",
        "            # Primeiro porto geralmente √© origem\n",
        "            if not result[\"Shipped_from\"]:\n",
        "                result[\"Shipped_from\"] = ports_found[0].split(',')[0] if ',' in ports_found[0] else ports_found[0]\n",
        "\n",
        "            # √öltimo porto geralmente √© destino\n",
        "            if len(ports_found) > 1 and not result[\"Shipped_To\"]:\n",
        "                result[\"Shipped_To\"] = ports_found[-1].split(',')[0] if ',' in ports_found[-1] else ports_found[-1]\n",
        "\n",
        "        # 4. BUSCA STATUS/DESCRIPTION\n",
        "        print(\"üìã Buscando status...\")\n",
        "        status_patterns = [\n",
        "            r\"Status[:\\s]+([^\\n\\r]+)\",\n",
        "            r\"(Loaded|Discharged|In Transit|Departed|Arrived)\",\n",
        "            r\"(LADEN|EMPTY|FULL)\"\n",
        "        ]\n",
        "\n",
        "        for pattern in status_patterns:\n",
        "            matches = re.findall(pattern, page_text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                status = matches[0].strip()\n",
        "                if not result[\"Description\"]:\n",
        "                    result[\"Description\"] = status\n",
        "                    print(f\"‚úÖ Status encontrado: {result['Description']}\")\n",
        "                    break\n",
        "\n",
        "        # 5. BUSCA LOCALIZA√á√ÉO ATUAL\n",
        "        print(\"üìç Buscando localiza√ß√£o atual...\")\n",
        "\n",
        "        # Procura por padr√µes de localiza√ß√£o\n",
        "        location_patterns = [\n",
        "            r\"Current Location[:\\s]+([^\\n\\r]+)\",\n",
        "            r\"Location[:\\s]+([^\\n\\r]+)\",\n",
        "            r\"At[:\\s]+([^\\n\\r]+)\",\n",
        "            r\"([A-Z][a-z]+,\\s*[A-Z]{2})\"  # Padr√£o Cidade, Pa√≠s\n",
        "        ]\n",
        "\n",
        "        for pattern in location_patterns:\n",
        "            matches = re.findall(pattern, page_text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                location = matches[0].strip()\n",
        "                if len(location) > 3 and not result[\"Location\"]:\n",
        "                    result[\"Location\"] = location\n",
        "                    print(f\"‚úÖ Localiza√ß√£o encontrada: {result['Location']}\")\n",
        "                    break\n",
        "\n",
        "        # 6. BUSCA DADOS ESPEC√çFICOS EM ELEMENTOS MSC\n",
        "        print(\"üîé An√°lise final dos elementos MSC...\")\n",
        "\n",
        "        # Debug: mostra alguns elementos MSC encontrados\n",
        "        msc_elements = soup.find_all('div', class_=re.compile(r'msc.*tracking'))\n",
        "        print(f\"üì¶ Elementos MSC encontrados: {len(msc_elements)}\")\n",
        "\n",
        "        for i, element in enumerate(msc_elements[:5]):  # Mostra apenas os primeiros 5\n",
        "            text = element.get_text(strip=True)\n",
        "            if text and len(text) > 10:\n",
        "                print(f\"   Elemento {i+1}: {text[:100]}...\")\n",
        "\n",
        "        # Procura por datas no formato espec√≠fico visto no output anterior\n",
        "        date_pattern = r\"(\\d{1,2}/\\d{1,2}/\\d{4})\"\n",
        "        dates_found = re.findall(date_pattern, page_text)\n",
        "\n",
        "        if dates_found:\n",
        "            print(f\"üìÖ Datas encontradas na p√°gina: {dates_found}\")\n",
        "\n",
        "            # Se ainda n√£o tem ETA, usa estrat√©gia espec√≠fica\n",
        "            if not result[\"POD_ETA\"]:\n",
        "                # Busca por contexto que indica ETA\n",
        "                for date in dates_found:\n",
        "                    # Busca o contexto ao redor da data\n",
        "                    date_context = \"\"\n",
        "                    date_index = page_text.find(date)\n",
        "                    if date_index > 0:\n",
        "                        start = max(0, date_index - 50)\n",
        "                        end = min(len(page_text), date_index + 50)\n",
        "                        date_context = page_text[start:end].lower()\n",
        "\n",
        "                    # Verifica se o contexto indica ETA\n",
        "                    if any(indicator in date_context for indicator in ['eta', 'arrival', 'estimated', 'expected']):\n",
        "                        result[\"POD_ETA\"] = date\n",
        "                        print(f\"‚úÖ ETA encontrado por contexto: {result['POD_ETA']}\")\n",
        "                        break\n",
        "\n",
        "                # Se ainda n√£o encontrou, pega a data mais futura\n",
        "                if not result[\"POD_ETA\"]:\n",
        "                    future_dates = [date for date in dates_found if date >= \"01/07/2025\"]\n",
        "                    if future_dates:\n",
        "                        result[\"POD_ETA\"] = future_dates[-1]\n",
        "                        print(f\"‚úÖ ETA assumido (√∫ltima data futura): {result['POD_ETA']}\")\n",
        "\n",
        "        # √öltima tentativa: busca espec√≠fica no HTML por elementos que contenham ETA\n",
        "        if not result[\"POD_ETA\"]:\n",
        "            print(\"üîç Busca espec√≠fica no HTML por ETA...\")\n",
        "            # Busca usando Selenium para elementos que possam conter ETA\n",
        "            try:\n",
        "                eta_elements = driver.find_elements(By.XPATH, \"//*[contains(text(), 'ETA') or contains(text(), 'Arrival') or contains(text(), 'Expected')]\")\n",
        "                for element in eta_elements:\n",
        "                    text = element.text\n",
        "                    date_match = re.search(r'(\\d{1,2}/\\d{1,2}/\\d{4})', text)\n",
        "                    if date_match:\n",
        "                        result[\"POD_ETA\"] = date_match.group(1)\n",
        "                        print(f\"‚úÖ ETA encontrado via Selenium: {result['POD_ETA']}\")\n",
        "                        break\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        # Procura por c√≥digos de porto (3 letras mai√∫sculas)\n",
        "        port_codes = re.findall(r'\\b[A-Z]{3}\\b', page_text)\n",
        "        if port_codes:\n",
        "            # Remove c√≥digos comuns que n√£o s√£o portos\n",
        "            actual_ports = [code for code in port_codes if code not in ['MSC', 'BIC', 'USA', 'CNN', 'LCA']]\n",
        "            if actual_ports:\n",
        "                if not result[\"Port_of_Load\"]:\n",
        "                    result[\"Port_of_Load\"] = actual_ports[0]\n",
        "                if len(actual_ports) > 1 and not result[\"Shipped_To\"]:\n",
        "                    result[\"Shipped_To\"] = actual_ports[-1]\n",
        "\n",
        "        # Contagem de dados encontrados\n",
        "        found_count = sum(1 for v in result.values() if v and v != \"success\" and not v.startswith(\"20\"))\n",
        "        print(f\"üìä {found_count} campos preenchidos\")\n",
        "\n",
        "        # Se n√£o encontrou dados importantes, marca como aviso\n",
        "        if not result[\"POD_ETA\"] and found_count < 3:\n",
        "            result[\"status\"] = \"warning\"\n",
        "            result[\"message\"] = \"Poucos dados encontrados - verifique BL\"\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"message\": f\"Erro ao extrair dados: {str(e)}\"\n",
        "        }\n",
        "\n",
        "def track_msc_shipment(site_url, bl_number):\n",
        "    \"\"\"Fun√ß√£o principal otimizada para MSC\"\"\"\n",
        "    driver = None\n",
        "    try:\n",
        "        print(f\"üöÄ Iniciando tracking MSC...\")\n",
        "        print(f\"üìã BL: {bl_number}\")\n",
        "\n",
        "        driver = setup_driver()\n",
        "\n",
        "        # Acessa site\n",
        "        driver.get(site_url)\n",
        "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
        "        print(\"‚úÖ Site acessado\")\n",
        "\n",
        "        # Lida com cookies\n",
        "        handle_cookies_and_overlays(driver)\n",
        "\n",
        "        # Encontra e preenche campo\n",
        "        input_field = WebDriverWait(driver, 10).until(\n",
        "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[placeholder*='Container']\"))\n",
        "        )\n",
        "\n",
        "        input_field.clear()\n",
        "        input_field.send_keys(bl_number)\n",
        "        input_field.send_keys(Keys.RETURN)\n",
        "        print(\"‚úÖ BL submetido\")\n",
        "\n",
        "        # Extrai dados\n",
        "        result = extract_msc_tracking_data(driver)\n",
        "\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"message\": f\"Erro: {str(e)}\"\n",
        "        }\n",
        "    finally:\n",
        "        if driver:\n",
        "            driver.quit()\n",
        "\n",
        "# TESTE FINAL\n",
        "if __name__ == \"__main__\":\n",
        "    site_url = \"https://www.msc.com/en/track-a-shipment\"\n",
        "    bl_number = \"MEDUHJ352259\"\n",
        "\n",
        "    print(\"üéØ TESTE FINAL - MSC TRACKING\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    result = track_msc_shipment(site_url, bl_number)\n",
        "\n",
        "    print(\"\\nüìä RESULTADO FINAL:\")\n",
        "    print(json.dumps(result, indent=2, ensure_ascii=False))\n",
        "\n",
        "    # Resumo dos dados encontrados\n",
        "    print(\"\\nüìã RESUMO:\")\n",
        "    for key, value in result.items():\n",
        "        if value and key not in [\"status\", \"timestamp\"]:\n",
        "            print(f\"  {key}: {value}\")"
      ]
    }
  ]
}